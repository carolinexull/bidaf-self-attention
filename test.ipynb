{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"{\n",
    "    'context': context,\n",
    "    'gold_sentence': gold_sentence,\n",
    "    'question': question,\n",
    "    'label': label,\n",
    "    'answer': {'text': xxx, 'answer_start': xxx}\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = 11873, no_answer = 5945, no_plausible = 15\n"
     ]
    }
   ],
   "source": [
    "import ujson as json\n",
    "with open('./external/dev-v2.0-preprocessed.json') as fh:\n",
    "    data_set = json.load(fh)\n",
    "no_plausible_answer = 0\n",
    "no_answer = 0\n",
    "for data in data_set:\n",
    "    if not data['label']:\n",
    "        no_answer += 1\n",
    "    if not data['answer']:\n",
    "        no_plausible_answer += 1\n",
    "print(f'total = {len(data_set)}, no_answer = {no_answer}, no_plausible = {no_plausible_answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got answer = 0.9001431820096017\n",
      "expected = 0.9001431820096017\n"
     ]
    }
   ],
   "source": [
    "# get_score\n",
    "def get_score(predicteds, ground_truths):\n",
    "    \"\"\" Return scores to evaluate, which is \n",
    "        `(yes/yes * 0.8 + no/no)/count`\n",
    "        predicteds should be an array containing all\n",
    "        predicted results which should be yes or no\n",
    "    \"\"\"\n",
    "    assert(len(predicteds) == len(ground_truths))\n",
    "    yes = 0\n",
    "    no = 0\n",
    "    for i in range(len(predicteds)):\n",
    "        if predicteds[i] == ground_truths[i]:\n",
    "            if predicteds[i]:\n",
    "                yes += 1\n",
    "            else:\n",
    "                no += 1\n",
    "    score = (yes * 0.8 + no)/len(predicteds)\n",
    "    return score\n",
    "\n",
    "def test_get_score():\n",
    "    predicteds = [True] * (11873 - 5945) + [False] * (5945)\n",
    "    ground_truths = predicteds\n",
    "    expected = ((11873 - 5945) * 0.8 + 5945)/11873\n",
    "    print(f'got answer = {get_score(predicteds, ground_truths)}\\nexpected = {expected}')\n",
    "\n",
    "test_get_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
